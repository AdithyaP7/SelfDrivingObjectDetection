{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionFinalPart1ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdithyaP7/SelfDrivingObjectDetection/blob/master/ObjectDetectionFinalPart1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxWDncyvryi6",
        "colab_type": "text"
      },
      "source": [
        "The aim of this project is to build and AI tool that can help Self Driving Cars \"see\" and pick up on objects that are on the road and classify them into different cateogries of what could be on the road.\n",
        "\n",
        "\n",
        "\n",
        "**Click on this image for a demo of what this project aims to build!**\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[<img src=\"https://i.ytimg.com/vi/2lxO_0FMalY/maxresdefault.jpg\" width=\"500\"/>](https://www.youtube.com/watch?v=9ydhDQaLAqM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAXDxK2m0d5z",
        "colab_type": "text"
      },
      "source": [
        "# Run the Cell Below to Download the Data and prepare the environment we are working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0vd1dK90K6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b73ed9f8-8844-4300-f5d9-85ffd1807fcb"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "\n",
        "# Load data\n",
        "def load_cifar10():\n",
        "  (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = cifar10.load_data()\n",
        "  y_train_cifar = y_train_cifar.squeeze()\n",
        "  y_test_cifar = y_test_cifar.squeeze()\n",
        "  return (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar)\n",
        "\n",
        "# CIFAR100 classes\n",
        "idx_to_class = ['background', 'car', 'truck']\n",
        "\n",
        "# Construct vehicle dataset from CIFAR10\n",
        "def construct_vehicle_dataset(data, labels, images_per_class, label_car=1, label_truck=9):\n",
        "  mask_car = labels == label_car\n",
        "  mask_truck = labels == label_truck\n",
        "\n",
        "  mask_vehicles = mask_car | mask_truck\n",
        "  mask_background = np.invert(mask_vehicles)\n",
        "  \n",
        "  data_car = data[mask_car]\n",
        "  data_truck = data[mask_truck]\n",
        "  data_background = data[mask_background][:images_per_class]\n",
        "\n",
        "  new_data = np.vstack((data_background, data_car, data_truck))\n",
        "  new_labels = np.repeat(np.array([0, 1, 2]), images_per_class, axis=0)\n",
        "  \n",
        "  return new_data, new_labels\n",
        "\n",
        "def load_vehicle_dataset():\n",
        "  (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = load_cifar10()\n",
        "  x_train, y_train = construct_vehicle_dataset(x_train_cifar, y_train_cifar, 5000)\n",
        "  x_test, y_test = construct_vehicle_dataset(x_test_cifar, y_test_cifar, 1000)\n",
        "  return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "# Helper functions\n",
        "\n",
        "# plotting\n",
        "def plot_one_image(data, labels = [], index = None, image_shape = None):\n",
        "  '''\n",
        "  if data is a single image, display that image\n",
        "\n",
        "  if data is a 4d stack of images, display that image\n",
        "  '''\n",
        "  ### cv2.imshow('image', data)    \n",
        "  num_dims   = len(data.shape)\n",
        "  num_labels = len(labels)\n",
        "  if image_shape is not None:\n",
        "    target_shape = image_shape\n",
        "  else:\n",
        "    target_shape = (32, 32, 3)\n",
        "  # reshape data if necessary\n",
        "  if num_dims == 1:\n",
        "    data = data.reshape(target_shape)\n",
        "  if num_dims == 2:\n",
        "    data = data.reshape(np.vstack[-1, image_shape])\n",
        "  num_dims   = len(data.shape)\n",
        "\n",
        "  # check if single or multiple images\n",
        "  if num_dims == 3:\n",
        "    if num_labels > 1:\n",
        "      print('Multiple labels does not make sense for single image.')\n",
        "      return\n",
        "\n",
        "    label = labels      \n",
        "    if num_labels == 0:\n",
        "      label = ''\n",
        "    image = data\n",
        "\n",
        "  if num_dims == 4:\n",
        "    image = data[index, :]\n",
        "    label = labels[index]\n",
        "\n",
        "  # plot image of interest\n",
        "  print('Label: %s'%label)\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "def model_to_string(model):\n",
        "  import re\n",
        "  stringlist = []\n",
        "  model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "  sms = \"\\n\".join(stringlist)\n",
        "  sms = re.sub('_\\d\\d\\d','', sms)\n",
        "  sms = re.sub('_\\d\\d','', sms)\n",
        "  sms = re.sub('_\\d','', sms)  \n",
        "  return sms\n",
        "\n",
        "def normalize(data):\n",
        "  # CIFAR100 mean (0.4914, 0.4822, 0.4465) std (0.2023, 0.1994, 0.2010)\n",
        "  return (data/255-np.array((0.4914, 0.4822, 0.4465))) / np.array((0.2023, 0.1994, 0.2010))\n",
        "\n",
        "def label_to_onehot(labels):\n",
        "  final_labels = np.zeros((len(labels), 3))\n",
        "  for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    if label == 0:\n",
        "      final_labels[i,:] = np.array([1, 0, 0])\n",
        "    if label == 1:\n",
        "      final_labels[i,:] = np.array([0, 1, 0])\n",
        "    if label == 2:\n",
        "      final_labels[i,:] = np.array([0, 0, 1])\n",
        "  return final_labels\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "  history = history.history\n",
        "  history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "  history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "  best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "  if not ax:\n",
        "    f, ax = plt.subplots(1,1)\n",
        "  sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "  sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "  ax.axhline(0.333, linestyle = '--',color='red', label = 'Chance')\n",
        "  ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "  ax.legend(loc = 1)    \n",
        "  ax.set_ylim([0.01, 1])\n",
        "\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel('Accuracy (Fraction)')\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am2Oe87hihZA",
        "colab_type": "text"
      },
      "source": [
        "# Milestone 1. Understanding our task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ULauRiUnva",
        "colab_type": "text"
      },
      "source": [
        "## Self Driving Cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL0PZLszVLsc",
        "colab_type": "text"
      },
      "source": [
        "We'll start by understanding our problem, identifying:\n",
        "\n",
        "What are potential benefits of self-driving cars? \n",
        "*   More Convenient For Drivers who are distracted easily by other devices; their full attention doesn't need to be on the road. \n",
        "*   More Environmentally friendly as self driving cars will not drive erratically by acclerating and breaking hard as this kind of behavior leads to more emmisions by a car\n",
        "*   Very Efficient Self Driving Algorithms can prevent human errors that cause accidents, problems that are both hazardous and very inconvient on a day to day basis \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "How do self-driving cars work? \n",
        "\n",
        "How do self-driving cars see? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqm6BqAPwPFI",
        "colab_type": "text"
      },
      "source": [
        "## Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryH-OYB7wdOX",
        "colab_type": "text"
      },
      "source": [
        "What Is the input of this Machine Learning Model?\n",
        "*   The Model should accept any type of media from a dash-cam or any other resource that can be used to capture footage from a road\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Given the input, what is the output of the object detection task?\n",
        "\n",
        "*   Ideally, the object detection task should produce some sort of classification of what a camera sees on the road. \n",
        "*   The Visualization of what users can see should be boxes of classification around an object\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIOd_yqVVxom",
        "colab_type": "text"
      },
      "source": [
        "The first step is to build an image classifier to recognize cars on the road cars\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lb-mORcVaMI",
        "colab_type": "text"
      },
      "source": [
        "# Milestone 2. Understanding our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g94jZ8bIDvvh",
        "colab_type": "text"
      },
      "source": [
        "## What data do we have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1OYUQBoqAh1",
        "colab_type": "text"
      },
      "source": [
        "One commonly used dataset for object recognition is CIFAR10. There are 10 classes in CIFAR10, including airplane, car, bird, cat, deer, dog, frog, horse, ship, truck. \n",
        "\n",
        "As we are trying to build a image classifier for self-driving cars, detecting cars is more of interest to us. \n",
        "\n",
        "Therefore, here we use a vehicle dataset, which contains the images in the car and truck categories, as well as some randomly chosen images from other categories in the CIFAR10 dataset.\n",
        "\n",
        "We use `load_vehicle_dataset()` to load the images in both the training set and the test set.\n",
        "\n",
        "Run The Cell Below to set the load vehicle dataset into variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qP5mLh7U00D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_vehicle_dataset()\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh4rmliVDaon",
        "colab_type": "text"
      },
      "source": [
        "Here, `x` contains the images and `y` contains the corresponding class labels. \n",
        "\n",
        "Let's first get a better understanding of the dataset by looking into the labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUqNQ0hnCO6v",
        "colab_type": "text"
      },
      "source": [
        "*Info on the dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQK_cWxFD6Ix",
        "colab_type": "text"
      },
      "source": [
        "`y_train` and `y_test` are 2 numpy arrays of our images' labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ9fBKusGXqY",
        "colab_type": "text"
      },
      "source": [
        "The shape of a numpy array is stored in the `shape` attribute, so we can check the shape of the training set label by `y_train.shape`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5dlllnKEi96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6252fccf-1d28-40bb-8b29-12d517478b7d"
      },
      "source": [
        "print('Our labels are stored as %s in Python' % type(y_train))\n",
        "print('The label vector of the training set has dimensions of (%d, )' % y_train.shape)\n",
        "print('The label vector of the test set has dimensions of (%d, )' % y_test.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our labels are stored as <class 'numpy.ndarray'> in Python\n",
            "The label vector of the training set has dimensions of (15000, )\n",
            "The label vector of the test set has dimensions of (3000, )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYKKmeCl9_rl",
        "colab_type": "text"
      },
      "source": [
        "Each object catogory is represented in a number as the label in the `y` vectors. \n",
        "\n",
        "Class names have been saved in the list `idx_to_class`, where the indices are the labels and the elements are class names. Eg. `idx_to_class[1]` is `car`, this means each `car` image has a label `1` in the `y` vector.\n",
        "\n",
        "Listed are examples of the different classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjFAIHHoAzLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b5753d2-32db-48a7-fb7d-fb018e48c256"
      },
      "source": [
        "print(idx_to_class[0])\n",
        "print(idx_to_class[1])\n",
        "print(idx_to_class[2])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'background'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmE9b7zECu36",
        "colab_type": "text"
      },
      "source": [
        "### Occurance of Elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_N8hpXYIpT_",
        "colab_type": "text"
      },
      "source": [
        "We also want to know how many images we have in each class. The `Counter` class in the `collections` package can count the occurrence of different elements for us. For example:\n",
        "\n",
        "```\n",
        "l = [1, 2, 3, 3, 4, 5, 5, 5]\n",
        "counter = collections.Counter(l)\n",
        "print(counter)\n",
        "```\n",
        "\n",
        "We can get:\n",
        "```\n",
        "Counter({5: 3, 3: 2, 1: 1, 2: 1, 4: 1})\n",
        "```\n",
        "\n",
        "Run the cell below to check the number of images we have in each object category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBl0ePbHE0s6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cfab5a6f-eeb6-4e3d-f33b-51dac6e619cf"
      },
      "source": [
        "import collections\n",
        "\n",
        "counter = collections.Counter(y_train)\n",
        "counter1 = collections.Counter(y_test)\n",
        "print(counter)\n",
        "print(counter1)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 5000, 1: 5000, 2: 5000})\n",
            "Counter({0: 1000, 1: 1000, 2: 1000})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBHUX917wkeo",
        "colab_type": "text"
      },
      "source": [
        "## What does our data look like? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uA4zJPqF1oC",
        "colab_type": "text"
      },
      "source": [
        "Next, let's take a look at the images in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86FTqK8JwDjk",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDEDVcREGGfY",
        "colab_type": "text"
      },
      "source": [
        "The images in the training and test sets are stored as numpy arrays in `x_train` and `x_test` respectively. \n",
        "\n",
        "Run the cell below to get the shape of these 2 arrays. The first value represents the number of images, the next two represent the height and width respectively, and the last one represents the number of colors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP74pX8NHlyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b3bc3c3c-a8e0-4685-da22-27111ec392a3"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15000, 32, 32, 3)\n",
            "(3000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WxXax6-FkMj",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the Image \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJibNL7CzXrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7dba785e-6f21-46c0-aa1b-1b2397b5e4a6"
      },
      "source": [
        "# plot a SINGLE image\n",
        "image = x_train[1]\n",
        "label = [idx_to_class[y_train[1]]]\n",
        "plot_one_image(x_train[1], [idx_to_class[y_train[1]]]) \n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: ['background']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuxN0RkihuB",
        "colab_type": "text"
      },
      "source": [
        "The next step is to build a classifier using neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AJzmg0drIYP",
        "colab_type": "text"
      },
      "source": [
        "# Milestone 3. Building a Neural Networks (Perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA1Rc_u3KoJT",
        "colab_type": "text"
      },
      "source": [
        "![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9S6SDcM8N9",
        "colab_type": "text"
      },
      "source": [
        "Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction. \n",
        "\n",
        "**In terms of this problem, what do each of the 4 blue neurons correspond to?**\n",
        "\n",
        "*   The Output layer is what gives us the classification of the object we are trying to determine\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dik5yhBOERG",
        "colab_type": "text"
      },
      "source": [
        "## Building the networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8PrEOTbhgNN",
        "colab_type": "text"
      },
      "source": [
        "**Run the Cell Below to Import Tensorflow, our Machine Learning tool.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqFAnQCxsgRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPOqTta1sb6e",
        "colab_type": "text"
      },
      "source": [
        "Before we train the model or use it to predict something, we have to **create** the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yus22AQpsqMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create our model by specifying and compiling it\n",
        "model = Sequential()\n",
        "model.add(Dense(4, input_shape=(3,),activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "model.compile(loss='mean_squared_error',\n",
        "                optimizer='adam',\n",
        "                metrics=['mean_squared_error'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "781M4IyhssuA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Here is a walk though what each of these lines of code means.**\n",
        "\n",
        "\n",
        "**1. Specify model**\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "In this line of code, we build our network where the information flows from left to right through the network in one direction as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n",
        "\n",
        "\n",
        "**2. Add layers to the network**\n",
        "```\n",
        "model.add(Dense(4,input_shape = (3,), activation = 'sigmoid'))\n",
        "```\n",
        "In this code, we `add` a `layer` of neurons to our network. \n",
        "\n",
        "This layers consists of 4 neurons. Each neuron is dense and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "```\n",
        "This code adds another layer to the network that has 1 neuron. This one neuron is used to predict a continuous value.\n",
        "\n",
        "**3. Turn the model on by compiling it** \n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'turn it on' and 'compile' it. To turn it on, we have to specify at the very least, a loss, an optimizer, and some ways of evaluating the model (metrics). \n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer = 'adam',\n",
        "metrics = ['mean_squared_error'])\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toYjQUOVtKDT",
        "colab_type": "text"
      },
      "source": [
        "Once we've created our network, we can use it very simply. Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`. \n",
        "\n",
        "```\n",
        "model.fit(x, y)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aozkfBxtWa7",
        "colab_type": "text"
      },
      "source": [
        "To use the model, you can use it to predict something with:\n",
        "```\n",
        "y = model.predict_classes(x)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyLV1oHjT62K",
        "colab_type": "text"
      },
      "source": [
        "# Milestone 4. Applying Neural Networks to Recognizing Vehicles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hBp4yqqoJF65"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PD3Z0QamJF68"
      },
      "source": [
        "\n",
        "In our problem, we are given `images` of shape `(32, 32, 3)`, each assigned to one of 3 labels: car, truck, others. We want to identify the key things that we need to design our network. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K-7tm6ZlJF7G"
      },
      "source": [
        "## Activity 1. Building our custom neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e8pozxKuJF7I"
      },
      "source": [
        "### Key Points "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UN4Pyw4qJF7N"
      },
      "source": [
        "We will build a simple 2-layer network for the model\n",
        "\n",
        "\n",
        "For our model, we have as our layers: \n",
        "* Input Layer:  However many inputs there are.\n",
        "* Layer 1 (Hidden): 128 neurons that are activated by `'relu'`\n",
        "* Layer 2 (Output): 3 neurons (1 per possible predicted class) that should have an appropriate activation. \n",
        "* We will compile with the `optimizers.SGD(lr=1e-3, momentum=0.9)` optimizer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LzFTOYMiJF7Q"
      },
      "source": [
        "###Build The Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZJUSGm_oJF7h",
        "colab": {}
      },
      "source": [
        "perceptron = Sequential()\n",
        "\n",
        "perceptron.add(Flatten(input_shape = (32,32,3)))\n",
        "perceptron.add(Dense(128, activation='relu'))\n",
        "perceptron.add(Dense(3, activation = 'softmax'))\n",
        "perceptron.compile(loss = 'categorical_crossentropy', optimizer = optimizers.SGD(lr=1e-3, momentum=0.9), metrics = ['accuracy'])\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nayBlbHmj4Ii",
        "colab_type": "text"
      },
      "source": [
        "### Training the model \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AItvQJE5NY0H",
        "colab_type": "text"
      },
      "source": [
        "Let's now train our perceptron on images from the train data. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s41zgK7lFQtT",
        "colab_type": "text"
      },
      "source": [
        "Before training the model, we need to preprocess the data for better training. \n",
        "Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. We have implemented this in the `normalize(input_data)` for you.\n",
        "\n",
        "Besides, we need to convert the label for each image into a one-hot vector, which means, for example, we represent label 2 (truck) as a vector `[0, 0, 1]`, so that the model output can be directly compared with the data label. This has been implemented in the `label_to_onehot(labels)` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjgTdXv6Kh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PeIseTjM7uG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "46cbe444-721b-43c0-bbd1-1a9e00d2fa4f"
      },
      "source": [
        "monitor = ModelCheckpoint('./model.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Normalize the data.\n",
        "x_train_norm = normalize(x_train)\n",
        "x_test_norm = normalize(x_test)\n",
        "\n",
        "# Convert labels into one-hot numpy arrays.\n",
        "y_train_onehot = label_to_onehot(y_train)\n",
        "y_test_onehot = label_to_onehot(y_test)\n",
        "\n",
        "history = perceptron.fit(x_train_norm, y_train_onehot, epochs = 10, validation_data = (x_test_norm, y_test_onehot), shuffle = True, callbacks = [monitor])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.8663 - accuracy: 0.6305 - val_loss: 0.7416 - val_accuracy: 0.6920\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.6730 - accuracy: 0.7214 - val_loss: 0.7148 - val_accuracy: 0.6993\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.6040 - accuracy: 0.7563 - val_loss: 0.6924 - val_accuracy: 0.7153\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5561 - accuracy: 0.7765 - val_loss: 0.6919 - val_accuracy: 0.7217\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5131 - accuracy: 0.7969 - val_loss: 0.6725 - val_accuracy: 0.7200\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4794 - accuracy: 0.8143 - val_loss: 0.6845 - val_accuracy: 0.7300\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4379 - accuracy: 0.8307 - val_loss: 0.6933 - val_accuracy: 0.7287\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4078 - accuracy: 0.8446 - val_loss: 0.7124 - val_accuracy: 0.7330\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3764 - accuracy: 0.8603 - val_loss: 0.7277 - val_accuracy: 0.7337\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3429 - accuracy: 0.8728 - val_loss: 0.7483 - val_accuracy: 0.7180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttqZa25BVDeR",
        "colab_type": "text"
      },
      "source": [
        "As our model trained, it told us a few things. The most important things to us are:\n",
        "* how accurate it was when training on the training set (reported as `acc`) \n",
        "* how accurate it was on the test set (reported as `val_acc`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOkqi035XRE",
        "colab_type": "text"
      },
      "source": [
        "We can actually plot how how well our model did across epochs using the model's `history`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvhyL-jJ9rKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "40102433-b550-4c00-c762-05f43d824fc4"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "plot_acc(history)\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}